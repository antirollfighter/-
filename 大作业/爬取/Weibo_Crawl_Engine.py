# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'WeiBo_Pics_Crawl.ui'
#
# Created by: PyQt5 UI code generator 5.15.4
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.


# coding:utf-8
import threading
import traceback

import requests
import json
import random
import os
from urllib.parse import quote
from lxml import etree
import urllib3

urllib3.disable_warnings()


class Weibo_Pic_Spider:
    def __init__(self):
        self.search_api1 = 'https://m.weibo.cn/api/container/getIndex?containerid=100103type%3D3%26q%3D{}%26t%3D0'  # 移动端API搜索
        self.search_api2 = 'https://s.weibo.com/user?q={}&Refer=weibo_user'  # 静态网页搜索
        self.header2 = {
            "Accept": "image/avif,image/webp,image/apng,image/svg+xml,image/*,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.9",
            "Referer": "https://weibo.com/",
            'Sec-Ch-Ua': '"Not.A/Brand";v="8", "Chromium";v="114", "Google Chrome";v="114"',
            "Sec-Ch-Ua-Platform": "Windows",
            "Sec-Fetch-Dest": "image",
            "Sec-Fetch-Mode": "no-cors",
            "Sec-Fetch-Site": "cross-site",
            "User-Agent": self.get_ua(),
        }
        self.user_list = []

    def get_user_list1(self, key_word):
        full_url1 = self.search_api1.format(key_word)
        header2 = {'User-Agent': self.get_ua()}
        r = requests.get(full_url1, headers=header2)
        if r.status_code == 200:
            try:
                _json = json.loads(r.text)
                users = _json['data']['cards'][1].get('card_group')
                for user_ in users:
                    item = {}
                    user_info = user_.get('user')
                    item['user_name'] = user_info.get('screen_name')
                    item['user_id'] = user_info.get('id')
                    item['user_head_img'] = user_info.get('profile_image_url')
                    self.user_list.append(item)
            except:
                traceback.print_exc()

    # 解析出图片地址
    def get_user_list2(self, key_word):
        current_username = [user["user_name"] for user in self.user_list]
        full_url2 = self.search_api2.format(quote(key_word))
        r = requests.get(full_url2, headers=self.header2)
        if r.status_code == 200:
            try:
                res = etree.HTML(r.text)
                selector = res.xpath('//div[@id="pl_user_feedList"]/div')
                for data in selector:
                    item = {}
                    user_name = ''.join(data.xpath('.//div/a[1]//text()'))
                    if user_name in current_username:
                        # 根据API1获取的用户在这里不给予显示
                        continue
                    item['user_name'] = user_name
                    item['user_id'] = ''.join(data.xpath('./div[@class="info"]/div/a[@uid]/@uid'))
                    item['user_head_img'] = ''.join(data.xpath('.//div[@class="avator"]/a/img/@src'))
                    self.user_list.append(item)
            except:
                traceback.print_exc()

    def get_users(self, key_word):
        """
        通过API1和API2获取检索的用户信息
        :param key_word:
        :return:
        """
        self.get_user_list1(key_word)
        self.get_user_list2(key_word)
        if len(self.user_list) != 0:
            return self.user_list
        else:
            return False

    def set_start_url(self, user_id):
        container_id = '107603' + str(user_id)
        start_url = f'https://m.weibo.cn/api/container/getIndex?containerid={container_id}'
        self.start_url = start_url

    def get_pics_url(self):
        i = 1
        while True:
            url = self.start_url + '&page={}'.format(i)
            header2 = {'User-Agent': self.get_ua()}
            r = requests.get(url, headers=header2)
            _json = json.loads(r.text)
            items = _json["data"]["cards"]
            flag = _json['ok']
            if flag == 1:
                for v in items:
                    picslist = v.get('mblog')
                    if picslist is not None:
                        img_urls = picslist.get('pics')
                        if img_urls != None:
                            for img_url_ in img_urls:
                                img_url = img_url_['large']['url']
                                yield img_url
            else:
                break
            i += 1

    def get_ua(self):
        first_num = random.randint(55, 62)
        third_num = random.randint(0, 3200)
        fourth_num = random.randint(0, 140)
        os_type = [
            '(Windows NT 6.1; WOW64)', '(Windows NT 10.0; WOW64)', '(X11; Linux x86_64)',
            '(Macintosh; Intel Mac OS X 10_12_6)'
        ]
        chrome_version = 'Chrome/{}.0.{}.{}'.format(first_num, third_num, fourth_num)

        ua = ' '.join(['Mozilla/5.0', random.choice(os_type), 'AppleWebKit/537.36',
                       '(KHTML, like Gecko)', chrome_version, 'Safari/537.36']
                      )
        return ua

    def do_make_dirs(self, dir_path):
        try:
            os.makedirs(dir_path)
        except:
            pass

    def do_download_pic(self, pic_url, file_name, base_dir):
        r = requests.get(pic_url, headers=self.header2, verify=False)
        with open(base_dir + '/' + file_name, 'wb')as f:
            f.write(r.content)

    def get_img_bytes(self, img_url):
        try:
            r = requests.get(img_url, headers=self.header2)
            if r.status_code == 200:
                pic_bytes = r.content
                return pic_bytes
            else:
                return False
        except requests.exceptions:
            return False




